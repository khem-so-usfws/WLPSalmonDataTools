{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WLP_Salmon_Spawning_Survey_DataJoinSummary_v2.py\n",
    "### Version: 01/29/2025\n",
    "### Author: Khem So, khem_so@fws.gov, (971) 282-2193\n",
    "### Abstract: This Python 3 script pulls data from the Willapa NWR salmon spawning survey ArcGIS Online feature service and performs joins and merges to result in a combined Excel dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import pandas as pd\n",
    "from arcgis import GIS\n",
    "import time, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.AddMessage(\"Starting...\")\n",
    "\n",
    "### ArcGIS Online stores date-time information in UTC by default. This function uses the pytz package to convert time zones and can be used to convert from UTC (\"UTC\") to localized time. For example, localized \"US/Pacific\" is either Pacific Standard Time UTC-8 or Pacific Daylight Time UTC-7 depending upon time of year.\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "def change_timezone_of_field(df, source_date_time_field, new_date_time_field_suffix, source_timezone, new_timezone):\n",
    "    \"\"\"Returns the values in *source_date_time_field* with its timezone converted to a new timezone within a new field *new_date_time_field*\n",
    "    : param df: The name of the spatially enabled or pandas DataFrame containing datetime fields\n",
    "    : param source_date_time_field: The name of the datetime field whose timezone is to be changed\n",
    "    : param new_date_time_field_suffix: Suffix appended to the end of the name of the source datetime field. This is used to create the new date time field name.\n",
    "    : param source_timezone: The name of the source timezone\n",
    "    : param new_timezone: The name of the converted timezone. For possible values, see https://gist.github.com/heyalexej/8bf688fd67d7199be4a1682b3eec7568\n",
    "    \"\"\"\n",
    "    # Define the source timezone in the source_date_time_field\n",
    "    df[source_date_time_field] = df[source_date_time_field].dt.tz_localize(source_timezone)\n",
    "    # Define the name of the new date time field\n",
    "    new_date_time_field = f\"{source_date_time_field}{new_date_time_field_suffix}\"\n",
    "    # Convert the datetime in the source_date_time_field to the new timezone in a new field called new_date_time_field\n",
    "    df[new_date_time_field] = df[source_date_time_field].dt.tz_convert(new_timezone)\n",
    "\n",
    "### This function converts Python datetime64 fields to %m/%d/%Y %H:%M:%S %Z%z format\n",
    "def archive_dt_field(df):\n",
    "    \"\"\"Selects fields with data types of 'datetime64[ns, UTC]','datetime64[ns, US/Pacific]' and converts to %m/%d/%Y %H:%M:%S %Z%z format for archiving to Excel\n",
    "    : param df: The name of the spatially enabled or pandas DataFrame containing datetime fields\n",
    "    \"\"\"\n",
    "    archive_dt_field_list = df.select_dtypes(include=['datetime64[ns, UTC]', 'datetime64[ns, US/Pacific]', 'datetime64'])\n",
    "    for col in archive_dt_field_list:\n",
    "        df[col] = df[col].dt.strftime('%m/%d/%Y %H:%M:%S %Z%z')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Allow authentication via login to U.S. Fish & Wildlife Service ArcGIS Online account via ArcGIS Pro\n",
    "gis = GIS(\"pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Enter year of interest\n",
    "# uncomment next line to use ArcGIS interface, otherwise hard coding year\n",
    "# year = arcpy.GetParameterAsText(0)\n",
    "year = \"2024\"\n",
    "\n",
    "### Enter path for local file saving\n",
    "# uncomment next line to use ArcGIS interface, otherwise hard coding out_workspace\n",
    "# out_workspace = arcpy.GetParameterAsText(1)\n",
    "out_workspace = r\"C:\\Users\\kso\\OneDrive - DOI\\Desktop\"\n",
    "\n",
    "### Create timestamp for file naming\n",
    "t = time.localtime()\n",
    "timestamp = time.strftime('%Y-%m-%d_%H%M', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Paths to ArcGIS Online data\n",
    "# To populate Service ItemId, go to Feature Service webpage and in bottom right corner, click on the View link.\n",
    "# Current Feature Service webpage: https://fws.maps.arcgis.com/home/item.html?id=758626eec0fc4bc1a72b4e4c9bd1023c\n",
    "ServiceItemID = gis.content.get(\"758626eec0fc4bc1a72b4e4c9bd1023c\")\n",
    "\n",
    "### There are separate methods for pulling spatial versus non-spatial data into Python. Spatial layers will become Spatially Enabled DataFrame objects. Non-spatial data will become regular pandas DataFrame objects.\n",
    "## Define variables pointing to spatial layers\n",
    "MetadataLyr = ServiceItemID.layers[0]\n",
    "LiveFishLyr = ServiceItemID.layers[1]\n",
    "CarcassLyr = ServiceItemID.layers[2]\n",
    "## Create Spatially Enabled DataFrame objects\n",
    "sedfMetadata = pd.DataFrame.spatial.from_layer(MetadataLyr)\n",
    "sedfLiveFishLocation = pd.DataFrame.spatial.from_layer(LiveFishLyr)\n",
    "sedfCarcassLocation = pd.DataFrame.spatial.from_layer(CarcassLyr)\n",
    "\n",
    "## Define variables point to non-spatial (tabular) data\n",
    "Observer = r\"https://services.arcgis.com/QVENGdaPbd4LUkLV/arcgis/rest/services/service_c555c76424ca452d8dab8de4f8c25000/FeatureServer/3\"\n",
    "\n",
    "## Convert AGOL table to NumPy Array and then to pandas DataFrames\n",
    "naObserver = arcpy.da.TableToNumPyArray(Observer,[\"objectid\",\"globalid\",\"strFirstName\",\"strLastName\",\"parentglobalid\",\"CreationDate\",\"Creator\",\"EditDate\",\"Editor\"])\n",
    "dfObserver = pd.DataFrame(naObserver)\n",
    "\n",
    "arcpy.AddMessage(\"Downloaded data from ArcGIS Online...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert integer timestamps to datetime\n",
    "sedfCarcassLocation['CreationDate'] = pd.to_datetime(sedfCarcassLocation['CreationDate'], utc=True, unit='ms')\n",
    "sedfCarcassLocation['EditDate'] = pd.to_datetime(sedfCarcassLocation['EditDate'], utc=True, unit='ms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use change_timezone_of_field function to convert all datetime fields in dataframe from UTC to Pacific within new field with _Pacific suffix\n",
    "for df in [sedfMetadata, sedfLiveFishLocation, sedfCarcassLocation, dfObserver]:\n",
    "    for col in df.select_dtypes(include=['datetime64']).columns:\n",
    "        change_timezone_of_field(df, col, \"_Pacific\", \"UTC\", \"US/Pacific\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter sedfMetadata by single year\n",
    "sedfMetadataYYYY = sedfMetadata[sedfMetadata[\"dtmDate\"].dt.strftime('%Y') == year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export raw data frames as backup\n",
    "## Use archive_dt_field function to convert Python date time into format Excel can read more easily\n",
    "archive_dt_field(sedfMetadata)\n",
    "archive_dt_field(sedfLiveFishLocation)\n",
    "archive_dt_field(sedfCarcassLocation)\n",
    "archive_dt_field(dfObserver)\n",
    "\n",
    "## Create export paths for backup and writes to Excel spreadsheet\n",
    "writer = pd.ExcelWriter(os.path.join(out_workspace,('WLP_Salmon_Spawning_Survey_BKUP_' + timestamp + '.xlsx')))\n",
    "sedfMetadata.to_excel(writer, 'Metadata', index=False)\n",
    "sedfLiveFishLocation.to_excel(writer, 'Live Fish', index=False)\n",
    "sedfCarcassLocation.to_excel(writer, 'Carcasses', index=False)\n",
    "dfObserver.to_excel(writer, 'Observers', index=False)\n",
    "writer.close()\n",
    "\n",
    "arcpy.AddMessage(\"Exported raw data as Excel spreadsheet for backup...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create dfObserver2 data frame with concatenated surveyor names grouped by parentglobalid\n",
    "## Clean up names\n",
    "dfObserver[\"strFirstName\"] = dfObserver[\"strFirstName\"].str.strip()\n",
    "dfObserver[\"strLastName\"] = dfObserver[\"strLastName\"].str.strip()\n",
    "\n",
    "## Process dfObserver to get single concatenated field for full name\n",
    "dfObserver[\"strFullName\"] = dfObserver[\"strFirstName\"] + \" \" + dfObserver[\"strLastName\"]\n",
    "\n",
    "## Process dfObserver to remove curly brackets to allow for join based on GUID\n",
    "dfObserver = dfObserver.replace(\"{\",\"\", regex=True)\n",
    "dfObserver = dfObserver.replace(\"}\",\"\", regex=True)\n",
    "\n",
    "## Process dfObserver to get concatenated list of full surveyor names by survey\n",
    "dfObserver2 = dfObserver[[\"parentglobalid\", \"strFullName\"]]\n",
    "dfObserver2 = dfObserver2.groupby(\"parentglobalid\").agg({\"strFullName\": ', '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Join sedfMetadataYYYY with dfObserver\n",
    "dfMetadataObserver = pd.merge(sedfMetadataYYYY,dfObserver2, how=\"left\", left_on=\"globalid\", right_on=\"parentglobalid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manipulate date/time fields in dfMetadataObserver\n",
    "## Strip time from dtmDate_Pacific\n",
    "dfMetadataObserver[\"dtmDate_Pacific\"] = dfMetadataObserver[\"dtmDate_Pacific\"].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "## Calculate total survey time\n",
    "dfMetadataObserver[\"dtmManualTimeStart_dt\"] = dfMetadataObserver[\"dtmDate_Pacific\"] + \" \" + dfMetadataObserver[\"dtmManualTimeStart\"]\n",
    "dfMetadataObserver[\"dtmManualTimeStart_dt\"] = pd.to_datetime(dfMetadataObserver[\"dtmManualTimeStart_dt\"],format=\"%m/%d/%Y %H:%M\")\n",
    "\n",
    "dfMetadataObserver[\"dtmManualTimeEnd_dt\"] = dfMetadataObserver[\"dtmDate_Pacific\"] + \" \" + dfMetadataObserver[\"dtmManualTimeEnd\"]\n",
    "dfMetadataObserver[\"dtmManualTimeEnd_dt\"] = pd.to_datetime(dfMetadataObserver[\"dtmManualTimeEnd_dt\"],format=\"%m/%d/%Y %H:%M\")\n",
    "\n",
    "dfMetadataObserver[\"dtmManualTimeTotal\"] = dfMetadataObserver[\"dtmManualTimeEnd_dt\"] - dfMetadataObserver[\"dtmManualTimeStart_dt\"]\n",
    "\n",
    "dfMetadataObserver[\"dtmManualTimeTotal\"] = (dfMetadataObserver[\"dtmManualTimeTotal\"]).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reset dfMetadataObserver in desired order and drop unneeded fields\n",
    "dfMetadataObserver = dfMetadataObserver[[\"globalid\", \"strStream\", \"dtmDate_Pacific\", \"strFullName\", \"strTideStart\", \"strWeather\", \"dtmManualTimeStart\", \"dtmManualTimeTurn\", \"dtmManualTimeEnd\", \"dtmManualTimeTotal\", \"strStreamFlow\", \"strViewingConditions\", \"strViewingConditionsComments\", \"ysnLiveFish\", \"ysnCarcasses\", \"strComments\", \"CreationDate_Pacific\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Join dfMetadataObserver with sedfLiveFishLocation\n",
    "dfMetadataObserverLiveFish = pd.merge(dfMetadataObserver,sedfLiveFishLocation, how=\"inner\", left_on=\"globalid\", right_on=\"parentglobalid\")\n",
    "\n",
    "## Reset dfMetadataObserverLiveFish in desired order and drop unneeded fields\n",
    "dfMetadataObserverLiveFish = dfMetadataObserverLiveFish[['globalid_x', 'strStream', 'dtmDate_Pacific', 'ysnLiveFish', 'globalid_y', 'strLiveSpecies', 'strLiveSex', 'ysnPairs', 'ysnReddBuilding', 'intNumRedds', 'strLiveFishRedd', 'strReddID', 'SHAPE', 'CreationDate_Pacific_x']]\n",
    "## Define dfMetadataObserverLiveFish sort order\n",
    "dfMetadataObserverLiveFish = dfMetadataObserverLiveFish.sort_values(by=[\"strStream\", \"dtmDate_Pacific\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Join dfMetadataObserver with sedfCarcassLocation\n",
    "dfMetadataObserverCarcasses = pd.merge(dfMetadataObserver,sedfCarcassLocation, how=\"inner\", left_on=\"globalid\", right_on=\"parentglobalid\")\n",
    "## Reset dfMetadataObserverCarcasses in desired order and drop unneeded fields\n",
    "dfMetadataObserverCarcasses = dfMetadataObserverCarcasses[['globalid_x', 'strStream', 'dtmDate_Pacific', 'ysnCarcasses', 'globalid_y', 'strCarcassSpecies', 'strCarcassSex', 'strDecomposedFresh', 'intNumCarcasses', 'ysnCountedLast', 'SHAPE', 'CreationDate_Pacific']]\n",
    "## Define dfMetadataObserverCarcasses sort order\n",
    "dfMetadataObserverCarcasses = dfMetadataObserverCarcasses.sort_values(by=[\"strStream\", \"dtmDate_Pacific\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Live fish data entered prior to 11/5/2021 are in different format so before/after data frames needed\n",
    "dfMetadataObserverLiveFish_before20211105 = dfMetadataObserverLiveFish[(dfMetadataObserverLiveFish['CreationDate_Pacific_x'] < \"11/05/2021\")]\n",
    "dfMetadataObserverLiveFish_after20211105 = dfMetadataObserverLiveFish[(dfMetadataObserverLiveFish['CreationDate_Pacific_x'] >= \"11/05/2021\")]\n",
    "\n",
    "dfMetadataObserverLiveFish_before20211105 = dfMetadataObserverLiveFish_before20211105.copy()\n",
    "dfMetadataObserverLiveFish_after20211105 = dfMetadataObserverLiveFish_after20211105.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create fields for counting live fish entered before 11/5/2021\n",
    "dfMetadataObserverLiveFish_before20211105.loc[dfMetadataObserverLiveFish_before20211105['ysnReddBuilding'] == \"yes\", ['intReddBuilding']] = 1\n",
    "dfMetadataObserverLiveFish_before20211105.loc[dfMetadataObserverLiveFish_before20211105['ysnPairs'] == \"yes\", ['dblPairs']] = 0.5\n",
    "dfMetadataObserverLiveFish_before20211105.loc[dfMetadataObserverLiveFish_before20211105['strLiveSex'] == \"M\", ['intMales']] = 1\n",
    "dfMetadataObserverLiveFish_before20211105.loc[dfMetadataObserverLiveFish_before20211105['strLiveSex'] == \"F\", ['intFemales']] = 1\n",
    "dfMetadataObserverLiveFish_before20211105.loc[dfMetadataObserverLiveFish_before20211105['strLiveSex'] == \"Unk\", ['intUnknown']] = 1\n",
    "\n",
    "## Group by GUID, stream, date, and species; sum the numeric fields\n",
    "dfLiveFishSummary1 = dfMetadataObserverLiveFish_before20211105.groupby(['globalid_x', 'strLiveSpecies'], as_index=False, dropna= False).agg(\n",
    "    intNumRedds=('intNumRedds', 'sum'),\n",
    "    intReddBuilding=('intReddBuilding', 'sum'),\n",
    "    dblPairs=('dblPairs', 'sum'),\n",
    "    intMales=('intMales', 'sum'),\n",
    "    intFemales=('intFemales', 'sum'),\n",
    "    intUnknown=('intUnknown', 'sum')\n",
    ")\n",
    "\n",
    "## Create field for sum of live fish\n",
    "dfLiveFishSummary1['intLiveFish'] = dfLiveFishSummary1[['intMales', 'intFemales', 'intUnknown']].sum(axis=1)\n",
    "dfLiveFishSummary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMetadataObserverLiveFish_after20211105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create fields for counting live fish entered after 11/5/2021\n",
    "dfMetadataObserverLiveFish_after20211105.loc[dfMetadataObserverLiveFish_after20211105['ysnReddBuilding'] == \"yes\", ['intReddBuilding']] = 1\n",
    "dfMetadataObserverLiveFish_after20211105.loc[dfMetadataObserverLiveFish_after20211105['ysnPairs'] == \"yes\", ['dblPairs']] = 1\n",
    "dfMetadataObserverLiveFish_after20211105.loc[dfMetadataObserverLiveFish_after20211105['ysnPairs'] == \"yes\", ['intMales']] = 1\n",
    "dfMetadataObserverLiveFish_after20211105.loc[dfMetadataObserverLiveFish_after20211105['ysnPairs'] == \"yes\", ['intFemales']] = 1\n",
    "dfMetadataObserverLiveFish_after20211105.loc[dfMetadataObserverLiveFish_after20211105['strLiveSex'] == \"M\", ['intMales']] = 1\n",
    "dfMetadataObserverLiveFish_after20211105.loc[dfMetadataObserverLiveFish_after20211105['strLiveSex'] == \"F\", ['intFemales']] = 1\n",
    "dfMetadataObserverLiveFish_after20211105.loc[dfMetadataObserverLiveFish_after20211105['strLiveSex'] == \"Unk\", ['intUnknown']] = 1\n",
    "dfMetadataObserverLiveFish_after20211105.loc[((dfMetadataObserverLiveFish_after20211105['strLiveFishRedd'] == \"Live Fish and Redd\") | (dfMetadataObserverLiveFish_after20211105['strLiveFishRedd'] == \"Redd\")), ['intNumRedds']] = 1\n",
    "dfMetadataObserverLiveFish_after20211105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMetadataObserverLiveFish_after20211105.to_csv((os.path.join(out_workspace,('WLP_Salmon_Spawning_Survey_' + year + '_' + timestamp + '.csv'))), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Group by GUID, stream, date, and species; sum the numeric fields\n",
    "dfLiveFishSummary2 = dfMetadataObserverLiveFish_after20211105.groupby(['globalid_x', 'strLiveSpecies'], as_index=False, dropna= False).agg(\n",
    "    intNumRedds=('intNumRedds', 'sum'),\n",
    "    intReddBuilding=('intReddBuilding', 'sum'),\n",
    "    dblPairs=('dblPairs', 'sum'),\n",
    "    intMales=('intMales', 'sum'),\n",
    "    intFemales=('intFemales', 'sum'),\n",
    "    intUnknown=('intUnknown', 'sum')\n",
    ")\n",
    "\n",
    "## Create field for sum of live fish\n",
    "dfLiveFishSummary2['intLiveFish'] = dfLiveFishSummary2[['intMales', 'intFemales', 'intUnknown']].sum(axis=1)\n",
    "dfLiveFishSummary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combine live fish data from before and after 11/5/2021\n",
    "dfLiveFishSummary = pd.concat([dfLiveFishSummary1, dfLiveFishSummary2])\n",
    "dfLiveFishSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing live fish summary\n",
    "dfLiveFishSummary_test1 = dfMetadataObserverLiveFish_before20211105.groupby(['globalid_x', 'strStream', 'dtmDate_Pacific', 'strLiveSpecies'], dropna= False).agg(\n",
    "    intNumRedds=('intNumRedds', 'sum'),\n",
    "    intReddBuilding=('intReddBuilding', 'sum'),\n",
    "    dblPairs=('dblPairs', 'sum'),\n",
    "    intMales=('intMales', 'sum'),\n",
    "    intFemales=('intFemales', 'sum'),\n",
    "    intUnknown=('intUnknown', 'sum')\n",
    ")\n",
    "dfLiveFishSummary_test1['intLiveFish'] = dfLiveFishSummary_test1[['intMales', 'intFemales', 'intUnknown']].sum(axis=1)\n",
    "dfLiveFishSummary_test2 = dfMetadataObserverLiveFish_after20211105.groupby(['globalid_x', 'strStream', 'dtmDate_Pacific','strLiveSpecies'], dropna= False).agg(\n",
    "    intNumRedds=('intNumRedds', 'sum'),\n",
    "    intReddBuilding=('intReddBuilding', 'sum'),\n",
    "    dblPairs=('dblPairs', 'sum'),\n",
    "    intMales=('intMales', 'sum'),\n",
    "    intFemales=('intFemales', 'sum'),\n",
    "    intUnknown=('intUnknown', 'sum')\n",
    ")\n",
    "dfLiveFishSummary_test2['intLiveFish'] = dfLiveFishSummary_test2[['intMales', 'intFemales', 'intUnknown']].sum(axis=1)\n",
    "dfLiveFishSummary_test = pd.concat([dfLiveFishSummary_test1, dfLiveFishSummary_test2])\n",
    "dfLiveFishSummary_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLiveFishSummary_test = dfLiveFishSummary_test[['intLiveFish', 'intMales', 'intFemales', 'intUnknown', 'dblPairs', 'intReddBuilding', 'intNumRedds']]\n",
    "dfLiveFishSummary_test = dfLiveFishSummary_test.sort_values(by=[\"strStream\", \"dtmDate_Pacific\"])\n",
    "dfLiveFishSummary_test\n",
    "\n",
    "arcpy.AddMessage(\"Completed live fish summary...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create fields for counting carcasses\n",
    "## Assume that null ysnCountedLast is 'yes' if strDecomposedFresh is 'Decomposed'\n",
    "## Assume that null ysnCountedLast is 'no' if strDecomposedFresh is 'Fresh'\n",
    "# yes OR null and decomposed\n",
    "dfMetadataObserverCarcasses.loc[dfMetadataObserverCarcasses['ysnCountedLast'] == \"yes\", ['intCountedLast']] = dfMetadataObserverCarcasses['intNumCarcasses']\n",
    "dfMetadataObserverCarcasses.loc[(dfMetadataObserverCarcasses['ysnCountedLast'].isna()) & (dfMetadataObserverCarcasses['strDecomposedFresh'] == \"Decomposed\"), ['intCountedLast']] = dfMetadataObserverCarcasses['intNumCarcasses']\n",
    "\n",
    "# no OR null and fresh\n",
    "dfMetadataObserverCarcasses.loc[(dfMetadataObserverCarcasses['strCarcassSex'] == \"M\") & ((dfMetadataObserverCarcasses['ysnCountedLast'] == \"no\") |  ((dfMetadataObserverCarcasses['ysnCountedLast'].isna()) &  (dfMetadataObserverCarcasses['strDecomposedFresh'] == \"Fresh\"))) , ['intNewMales']] = dfMetadataObserverCarcasses['intNumCarcasses']\n",
    "dfMetadataObserverCarcasses.loc[(dfMetadataObserverCarcasses['strCarcassSex'] == \"F\") & ((dfMetadataObserverCarcasses['ysnCountedLast'] == \"no\") |  ((dfMetadataObserverCarcasses['ysnCountedLast'].isna()) &  (dfMetadataObserverCarcasses['strDecomposedFresh'] == \"Fresh\"))) , ['intNewFemales']] = dfMetadataObserverCarcasses['intNumCarcasses']\n",
    "dfMetadataObserverCarcasses.loc[(dfMetadataObserverCarcasses['strCarcassSex'] == \"J\") & ((dfMetadataObserverCarcasses['ysnCountedLast'] == \"no\") |  ((dfMetadataObserverCarcasses['ysnCountedLast'].isna()) &  (dfMetadataObserverCarcasses['strDecomposedFresh'] == \"Fresh\"))) , ['intNewJuveniles']] = dfMetadataObserverCarcasses['intNumCarcasses']\n",
    "dfMetadataObserverCarcasses.loc[(dfMetadataObserverCarcasses['strCarcassSex'] == \"Unk\") & ((dfMetadataObserverCarcasses['ysnCountedLast'] == \"no\") |  ((dfMetadataObserverCarcasses['ysnCountedLast'].isna()) &  (dfMetadataObserverCarcasses['strDecomposedFresh'] == \"Fresh\"))) , ['intNewUnknown']] = dfMetadataObserverCarcasses['intNumCarcasses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Group by GUID, stream, date, and species; sum the numeric fields; add field for new carcasses\n",
    "dfCarcassSummary = dfMetadataObserverCarcasses.groupby(by=['globalid_x', 'strCarcassSpecies'],  axis=0, level=None, as_index=False).agg(\n",
    "    intNumCarcasses=('intNumCarcasses', 'sum'),\n",
    "    intCountedLast=('intCountedLast', 'sum'),\n",
    "    intNewMales=('intNewMales', 'sum'),\n",
    "    intNewFemales=('intNewFemales', 'sum'),\n",
    "    intNewJuveniles=('intNewJuveniles', 'sum'),\n",
    "    intNewUnknown=('intNewUnknown', 'sum'),\n",
    ")\n",
    "dfCarcassSummary['intNewNumCarcasses'] = dfCarcassSummary['intNumCarcasses'] - dfCarcassSummary['intCountedLast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing carcasses summary\n",
    "dfCarcassSummary_test = dfMetadataObserverCarcasses.groupby(by=['globalid_x', 'strStream', 'dtmDate_Pacific', 'strCarcassSpecies'],  axis=0, level=None, dropna= False).agg(\n",
    "    intNumCarcasses=('intNumCarcasses', 'sum'),\n",
    "    intCountedLast=('intCountedLast', 'sum'),\n",
    "    intNewMales=('intNewMales', 'sum'),\n",
    "    intNewFemales=('intNewFemales', 'sum'),\n",
    "    intNewJuveniles=('intNewJuveniles', 'sum'),\n",
    "    intNewUnknown=('intNewUnknown', 'sum'),\n",
    ")\n",
    "dfCarcassSummary_test['intNewNumCarcasses'] = dfCarcassSummary_test['intNumCarcasses'] - dfCarcassSummary_test['intCountedLast']\n",
    "dfCarcassSummary_test = dfCarcassSummary_test.sort_values(by=[\"strStream\", \"dtmDate_Pacific\"])\n",
    "dfCarcassSummary_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.AddMessage(\"Completed carcass summary...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Copy dfMetadataObserver as start of summary data frames\n",
    "dfSummary = dfMetadataObserver.copy()\n",
    "# Calculate zeroes\n",
    "dfSummary.loc[dfSummary['ysnLiveFish'] == \"no\", ['intLiveFish']] = 0\n",
    "dfSummary.loc[dfSummary['ysnCarcasses'] == \"no\", ['intCarcasses']] = 0\n",
    "# Join\n",
    "dfLiveFishSummary = pd.merge(dfSummary,dfLiveFishSummary, how=\"left\", left_on=\"globalid\", right_on=\"globalid_x\")\n",
    "dfCarcassSummary = pd.merge(dfSummary,dfCarcassSummary, how=\"left\", left_on=\"globalid\", right_on=\"globalid_x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleanup dfLiveFishSummary\n",
    "dfLiveFishSummary.loc[(dfLiveFishSummary[\"intLiveFish_x\"].isna()), 'intLiveFish_x'] = 0\n",
    "dfLiveFishSummary.loc[(dfLiveFishSummary[\"intLiveFish_y\"].isna()), 'intLiveFish_y'] = 0\n",
    "dfLiveFishSummary[\"intLiveFish\"] = dfLiveFishSummary[\"intLiveFish_x\"] + dfLiveFishSummary[\"intLiveFish_y\"]\n",
    "dfLiveFishSummary = dfLiveFishSummary[['globalid', 'strStream', 'dtmDate_Pacific', 'strFullName', 'strTideStart', 'strWeather', 'dtmManualTimeStart', 'dtmManualTimeTurn', 'dtmManualTimeEnd', 'dtmManualTimeTotal', 'strStreamFlow', 'strViewingConditions', 'strViewingConditionsComments', 'ysnLiveFish', 'strLiveSpecies', 'intLiveFish', 'intMales', 'intFemales', 'intUnknown', 'intReddBuilding', 'dblPairs', 'intNumRedds', 'strComments']]\n",
    "dfLiveFishSummary = dfLiveFishSummary.sort_values(by=[\"strStream\", \"dtmDate_Pacific\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleanup dfCarcassSummary\n",
    "dfCarcassSummary.loc[(dfCarcassSummary[\"intCarcasses\"].isna()), 'intCarcasses'] = 0\n",
    "dfCarcassSummary.loc[(dfCarcassSummary[\"intNumCarcasses\"].isna()), 'intNumCarcasses'] = 0\n",
    "dfCarcassSummary[\"intTotalCarcasses\"] = dfCarcassSummary[\"intCarcasses\"] + dfCarcassSummary[\"intNumCarcasses\"]\n",
    "dfCarcassSummary = dfCarcassSummary[['globalid', 'strStream', 'dtmDate_Pacific', 'strFullName', 'strTideStart', 'strWeather', 'dtmManualTimeStart', 'dtmManualTimeTurn', 'dtmManualTimeEnd', 'dtmManualTimeTotal', 'strStreamFlow', 'strViewingConditions', 'strViewingConditionsComments', 'ysnCarcasses', 'strCarcassSpecies', 'intTotalCarcasses', 'intCountedLast', 'intNewNumCarcasses', 'intNewMales', 'intNewFemales', 'intNewJuveniles', 'intNewUnknown', 'strComments']]\n",
    "dfCarcassSummary = dfCarcassSummary.sort_values(by=[\"strStream\", \"dtmDate_Pacific\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export data frames\n",
    "## Use archive_dt_field function to convert Python date time into format Excel can read more easily\n",
    "archive_dt_field(dfMetadataObserver)\n",
    "archive_dt_field(dfMetadataObserverLiveFish)\n",
    "archive_dt_field(dfMetadataObserverCarcasses)\n",
    "archive_dt_field(dfLiveFishSummary)\n",
    "archive_dt_field(dfCarcassSummary)\n",
    "    \n",
    "## Create export paths for backup and writes to Excel spreadsheet\n",
    "writer = pd.ExcelWriter(os.path.join(out_workspace,('WLP_Salmon_Spawning_Survey_' + year + '_' + timestamp + '.xlsx')))\n",
    "dfMetadataObserver.to_excel(writer, 'Metadata', index=False)\n",
    "dfMetadataObserverLiveFish.to_excel(writer, 'Live Fish', index=False)\n",
    "dfMetadataObserverCarcasses.to_excel(writer, 'Carcasses', index=False)\n",
    "dfLiveFishSummary.to_excel(writer, 'Live Fish Summary', index=False)\n",
    "dfCarcassSummary.to_excel(writer, 'Carcass Summary', index=False)\n",
    "writer.close()\n",
    "\n",
    "arcpy.AddMessage(\"Summary data exported to Excel spreadsheet.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
