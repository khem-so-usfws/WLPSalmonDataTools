{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WLP_Salmon_Spawning_Survey_DataJoinSummary_v1.py\n",
    "### Version: 3/2/2022\n",
    "### Author: Khem So, khem_so@fws.gov, (503) 231-6839\n",
    "### Abstract: This Python 3 script pulls data from the HI Waterbirds Reproductive Success ArcGIS Online feature service and performs joins and merges to result in a combined CSV dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import pandas as pd\n",
    "from arcgis import GIS\n",
    "import time, os, fnmatch, shutil\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ArcGIS Online stores date-time information in UTC by default. This function uses the pytz package to convert time zones and can be used to convert from UTC (\"UTC\") to localized time. For example, localized \"US/Pacific\" is either Pacific Standard Time UTC-8 or Pacific Daylight Time UTC-7 depending upon time of year.\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "def change_timezone_of_field(df, source_date_time_field, new_date_time_field_suffix, source_timezone, new_timezone):\n",
    "    \"\"\"Returns the values in *source_date_time_field* with its timezone converted to a new timezone within a new field *new_date_time_field*\n",
    "    : param df: The name of the spatially enabled or pandas DataFrame containing datetime fields\n",
    "    : param source_date_time_field: The name of the datetime field whose timezone is to be changed\n",
    "    : param new_date_time_field_suffix: Suffix appended to the end of the name of the source datetime field. This is used to create the new date time field name.\n",
    "    : param source_timezone: The name of the source timezone\n",
    "    : param new_timezone: The name of the converted timezone. For possible values, see https://gist.github.com/heyalexej/8bf688fd67d7199be4a1682b3eec7568\n",
    "    \"\"\"\n",
    "    # Define the source timezone in the source_date_time_field\n",
    "    df[source_date_time_field] = df[source_date_time_field].dt.tz_localize(source_timezone)\n",
    "    # Define the name of the new date time field\n",
    "    new_date_time_field = source_date_time_field + new_date_time_field_suffix\n",
    "    # Convert the datetime in the source_date_time_field to the new timezone in a new field called new_date_time_field\n",
    "    df[new_date_time_field] = df[source_date_time_field].dt.tz_convert(new_timezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function converts Python datetime64 fields to %m/%d/%Y %H:%M:%S %Z%z format\n",
    "def archive_dt_field(df):\n",
    "    \"\"\"Selects fields with data types of 'datetime64[ns, UTC]','datetime64[ns, US/Pacific]' and converts to %m/%d/%Y %H:%M:%S %Z%z format for archiving to Excel\n",
    "    : param df: The name of the spatially enabled or pandas DataFrame containing datetime fields\n",
    "    \"\"\"\n",
    "    archive_dt_field_list = df.select_dtypes(include=['datetime64[ns, UTC]','datetime64[ns, US/Pacific]'])\n",
    "    for col in archive_dt_field_list:\n",
    "        df[col] = df[col].dt.strftime('%m/%d/%Y %H:%M:%S %Z%z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Allow authentication via login to U.S. Fish & Wildlife Service ArcGIS Online account via ArcGIS Pro\n",
    "gis = GIS(\"pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Enter year of interest\n",
    "# uncomment next line to use ArcGIS interface, otherwise hard coding year\n",
    "# year = arcpy.GetParameterAsText(0)\n",
    "year = \"2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Enter path for local file saving\n",
    "# uncomment next line to use ArcGIS interface, otherwise hard coding out_workspace\n",
    "# out_workspace = arcpy.GetParameterAsText(1)\n",
    "out_workspace = \"C:/Users/kso/Desktop/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create timestamp for file naming\n",
    "t = time.localtime()\n",
    "timestamp = time.strftime('%Y-%m-%d_%H%M', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Paths to ArcGIS Online data\n",
    "# To populate Service ItemId, go to Feature Service webpage and in bottom right corner, click on the View link.\n",
    "# Current Feature Service webpage: https://fws.maps.arcgis.com/home/item.html?id=758626eec0fc4bc1a72b4e4c9bd1023c\n",
    "ServiceItemID = gis.content.get(\"758626eec0fc4bc1a72b4e4c9bd1023c\")\n",
    "\n",
    "### There are separate methods for pulling spatial versus non-spatial data into Python. Spatial layers will become Spatially Enabled DataFrame objects. Non-spatial data will become regular pandas DataFrame objects.\n",
    "## Define variables pointing to spatial layers\n",
    "MetadataLyr = ServiceItemID.layers[0]\n",
    "LiveFishLyr = ServiceItemID.layers[1]\n",
    "CarcassLyr = ServiceItemID.layers[2]\n",
    "## Create Spatially Enabled DataFrame objects\n",
    "sedfMetadata = pd.DataFrame.spatial.from_layer(MetadataLyr)\n",
    "sedfLiveFishLocation = pd.DataFrame.spatial.from_layer(LiveFishLyr)\n",
    "sedfCarcassLocation = pd.DataFrame.spatial.from_layer(CarcassLyr)\n",
    "\n",
    "## Define variables point to non-spatial (tabular) data\n",
    "Observer = r\"https://services.arcgis.com/QVENGdaPbd4LUkLV/arcgis/rest/services/service_c555c76424ca452d8dab8de4f8c25000/FeatureServer/3\"\n",
    "\n",
    "## Convert AGOL table to NumPy Array and then to pandas DataFrames\n",
    "naObserver = arcpy.da.TableToNumPyArray(Observer,[\"objectid\",\"globalid\",\"strFirstName\",\"strLastName\",\"parentglobalid\",\"CreationDate\",\"Creator\",\"EditDate\",\"Editor\"])\n",
    "dfObserver = pd.DataFrame(naObserver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use change_timezone_of_field function to convert all datetime fields in dataframe from UTC to Pacific within new field with _Pacific suffix\n",
    "for col in sedfMetadata.columns:\n",
    "     if sedfMetadata[col].dtype == 'datetime64[ns]':\n",
    "         change_timezone_of_field(sedfMetadata, col, \"_Pacific\", \"UTC\", \"US/Pacific\")\n",
    "\n",
    "for col in sedfLiveFishLocation.columns:\n",
    "     if sedfLiveFishLocation[col].dtype == 'datetime64[ns]':\n",
    "         change_timezone_of_field(sedfLiveFishLocation, col, \"_Pacific\", \"UTC\", \"US/Pacific\")\n",
    "\n",
    "for col in sedfCarcassLocation.columns:\n",
    "     if sedfCarcassLocation[col].dtype == 'datetime64[ns]':\n",
    "         change_timezone_of_field(sedfCarcassLocation, col, \"_Pacific\", \"UTC\", \"US/Pacific\")\n",
    "\n",
    "for col in dfObserver.columns:\n",
    "     if dfObserver[col].dtype == 'datetime64[ns]':\n",
    "         change_timezone_of_field(dfObserver, col, \"_Pacific\", \"UTC\", \"US/Pacific\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter sedfMetadata by single year\n",
    "sedfMetadataYYYY = sedfMetadata[sedfMetadata[\"dtmDate\"].dt.strftime('%Y') == year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export raw data frames as backup\n",
    "## Use archive_dt_field function to convert Python date time into format Excel can read more easily\n",
    "archive_dt_field(sedfMetadata)\n",
    "archive_dt_field(sedfLiveFishLocation)\n",
    "archive_dt_field(sedfCarcassLocation)\n",
    "archive_dt_field(dfObserver)\n",
    "\n",
    "## Create export paths for backup and writes to Excel spreadsheet\n",
    "writer = pd.ExcelWriter(os.path.join(out_workspace,('WLP_Salmon_Spawning_Survey_BKUP_' + timestamp + '.xlsx')))\n",
    "sedfMetadata.to_excel(writer, 'Metadata')\n",
    "sedfLiveFishLocation.to_excel(writer, 'Live Fish')\n",
    "sedfCarcassLocation.to_excel(writer, 'Carcasses')\n",
    "dfObserver.to_excel(writer, 'Observers')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create dfObserver2 data frame with concatenated surveyor names grouped by parentglobalid\n",
    "## Process dfObserver to get single concatenated field for full name\n",
    "dfObserver[\"strFullName\"] = dfObserver[\"strFirstName\"] + \" \" + dfObserver[\"strLastName\"]\n",
    "\n",
    "## Process dfObserver to remove curly brackets to allow for join based on GUID\n",
    "dfObserver = dfObserver.replace(\"{\",\"\", regex=True)\n",
    "dfObserver = dfObserver.replace(\"}\",\"\", regex=True)\n",
    "\n",
    "## Process dfObserver to get concatenated list of full surveyor names by survey\n",
    "dfObserver2 = dfObserver[[\"parentglobalid\", \"strFullName\"]]\n",
    "dfObserver2 = dfObserver2.groupby(\"parentglobalid\").agg({\"strFullName\": ', '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Join sedfMetadataYYYY with dfObserver\n",
    "dfMetadataObserver = pd.merge(sedfMetadataYYYY,dfObserver2, how=\"left\", left_on=\"globalid\", right_on=\"parentglobalid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manipulate date/time fields in dfMetadataObserver\n",
    "## Strip time from dtmDate_Pacific\n",
    "dfMetadataObserver[\"dtmDate_Pacific\"] = dfMetadataObserver[\"dtmDate_Pacific\"].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "## Calculate total survey time\n",
    "dfMetadataObserver[\"dtmManualTimeStart_dt\"] = dfMetadataObserver[\"dtmDate_Pacific\"] + \" \" + dfMetadataObserver[\"dtmManualTimeStart\"]\n",
    "dfMetadataObserver[\"dtmManualTimeStart_dt\"] = pd.to_datetime(dfMetadataObserver[\"dtmManualTimeStart_dt\"],format=\"%m/%d/%Y %H:%M\")\n",
    "\n",
    "dfMetadataObserver[\"dtmManualTimeEnd_dt\"] = dfMetadataObserver[\"dtmDate_Pacific\"] + \" \" + dfMetadataObserver[\"dtmManualTimeEnd\"]\n",
    "dfMetadataObserver[\"dtmManualTimeEnd_dt\"] = pd.to_datetime(dfMetadataObserver[\"dtmManualTimeEnd_dt\"],format=\"%m/%d/%Y %H:%M\")\n",
    "\n",
    "dfMetadataObserver[\"dtmManualTimeTotal\"] = dfMetadataObserver[\"dtmManualTimeEnd_dt\"] - dfMetadataObserver[\"dtmManualTimeStart_dt\"]\n",
    "\n",
    "dfMetadataObserver[\"dtmManualTimeTotal\"] = (dfMetadataObserver[\"dtmManualTimeTotal\"]).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reset dfMetadataObserver in desired order and drop unneeded fields\n",
    "dfMetadataObserver = dfMetadataObserver[[\"globalid\", \"strStream\", \"dtmDate_Pacific\", \"strFullName\", \"strTideStart\", \"strWeather\", \"dtmManualTimeStart\", \"dtmManualTimeTurn\", \"dtmManualTimeEnd\", \"dtmManualTimeTotal\", \"strStreamFlow\", \"strViewingConditions\", \"strViewingConditionsComments\", \"ysnLiveFish\", \"ysnCarcasses\", \"strComments\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join dfMetadataObserver with sedfLiveFishLocation\n",
    "dfMetadataObserverLiveFish = pd.merge(dfMetadataObserver,sedfLiveFishLocation, how=\"inner\", left_on=\"globalid\", right_on=\"parentglobalid\")\n",
    "## Define dfMetadataObserverLiveFish sort order\n",
    "dfMetadataObserverLiveFish = dfMetadataObserverLiveFish.sort_values(by=[\"strStream\", \"dtmDate_Pacific\"])\n",
    "dfMetadataObserverLiveFish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join dfMetadataObserver with sedfCarcassLocation\n",
    "dfMetadataObserverCarcasses = pd.merge(dfMetadataObserver,sedfCarcassLocation, how=\"inner\", left_on=\"globalid\", right_on=\"parentglobalid\")\n",
    "## Define dfMetadataObserverCarcasses sort order\n",
    "dfMetadataObserverCarcasses = dfMetadataObserverCarcasses.sort_values(by=[\"strStream\", \"dtmDate_Pacific\"])\n",
    "dfMetadataObserverCarcasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export data frames\n",
    "## Use archive_dt_field function to convert Python date time into format Excel can read more easily\n",
    "archive_dt_field(dfMetadataObserver)\n",
    "archive_dt_field(dfMetadataObserverLiveFish)\n",
    "archive_dt_field(dfMetadataObserverCarcasses)\n",
    "\n",
    "## Create export paths for backup and writes to Excel spreadsheet\n",
    "writer = pd.ExcelWriter(os.path.join(out_workspace,('WLP_Salmon_Spawning_Survey_' + year + '_' + timestamp + '.xlsx')))\n",
    "dfMetadataObserver.to_excel(writer, 'Metadata')\n",
    "dfMetadataObserverLiveFish.to_excel(writer, 'Live Fish')\n",
    "dfMetadataObserverCarcasses.to_excel(writer, 'Carcasses')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
